# -*- coding: utf-8 -*-
"""convolution08.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tkU_ae-IERNlYkdWX_Ke86CM3w44tO4p
"""

# 합성곱(convolution)
# 마치 입력 데이터에 마법의 도장을 찍어서 유용한 특성만 드러나게 하는 것으로 비유할 수 있다.

# 인공 신경망의 모델 훈련
# 처음에 가중치 w1~wk와 절편 b를 랜덤하게 초기화한 다음 에포크를 반복하면서 경사 하강법 알고리즘을 사용하여 손실이 낮아지도록 최적의 가중치와 절편을 찾아간다.
# aw1 +,,,+cwk + b

# 합성곱 신경망(convolutional neural network, CNN)
# 뉴런 = 필터(filter) = 커널(kernel)
# kernel은 입력에 곱하는 가중치이다.
# filter는 뉴런 개수를 표현할 때 사용
# 특성 맵(feature map)은 합성곱 계산을 통해 얻은 출력을 의미
# 합성곱의 장점은 1차원이 아니라 2차원 입력에도 적용할 수 있다는 것.
# 합성공 신경망은 이미지 처리 분야에서 뛰어난 성능을 발휘

from tensorflow import keras
# Conv2D(filter의 개수)
# 커널의 크기는 하이퍼파라미터, 보통 (3,3) , (5,5) 크기가 권장됨
keras.layers.Conv2D(10, kernel_size=(3,3), activation='relu')

# 합성곱 층을 1개 이상 사용한 인공 신경망을 합성곱 신경망이라고 부름

# 입력 배열 주위를 가상의 원소로 채우는 것을 패딩(padding)이라고 함.
# ex) (4,4)크기를 (6,6)으로 만들때,, 0으로 채워넣음.
# 세임 패딩(same padding) : 입력과 특성 맵의 크기를 동일하게 만들기 위해 입력 주위에 0으로 패딩 하는 것을 의미
# 합성곱 신경망에서는 세임 패딩이 많이 사용됨.


# valid padding
# padding없이 순수한 입력 배열에서만 합성곱을 하여 특성 맵을 만드는 경우
# valid padding은 특성 맵의 크기가 줄어들 수 밖에 없다.

# stride
# 패딩 이동의 크기
# ex) (6,6)을 (3,3)으로 이동할 때, 그 이동의 크기를 나타내는 것을 의미.

keras.layers.Conv2D(10, kernel_size=(3,3), activation='relu', padding='same', strides=1)

# pooling
# 합성곱 층에서 만든 특성 맵의 가로세로 크기를 줄이는 역할을 수행한다.
# MaxPool2D(풀링의 크기)
keras.layers.MaxPool2D(2)
# 많은 경우 평균 풀링보다 최대 풀링을 많이 사용. 왜냐하면 평균 풀링은 특성 맵에 있는 중요한 정보를 (평균하여) 희석시킬 수 있기 때문

# 합성곱 신경망 사용해 이미지 분류

# 텐서플로를 사용하면 합성곱, 패딩, 풀링 크기를 직접 계산할 필요가 없다. 복잡한 계산은 케라스 API에 모두 위임하고 사용자는 직관적으로 신경망을 설계

from tensorflow import keras
from sklearn.model_selection import  train_test_split
(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()
train_scaled = train_input.reshape(-1, 28, 28, 1) / 255.0
train_scaled, val_scaled, train_target, val_target = train_test_split(train_scaled, train_target, test_size=0.2, random_state=42)

# 합성곱 만들기.

model = keras.Sequential()
# 첫번째 풀링층 : (14,14,32)
model.add(keras.layers.Conv2D(32, kernel_size=3, activation='relu', padding='same', input_shape=(28,28,1)))
model.add(keras.layers.MaxPooling2D(2))

# 두번째 풀링층 : (7,7,64)
model.add(keras.layers.Conv2D(64, kernel_size=3, activation='relu', padding='same'))
model.add(keras.layers.MaxPooling2D(2))


# 이 3차원 특성 맵을 일렬로 펼침
model.add(keras.layers.Flatten())
model.add(keras.layers.Dense(100, activation='relu'))
model.add(keras.layers.Dropout(0.4))
model.add(keras.layers.Dense(10, activation='softmax'))

model.summary()
# param 개수 계산
# (3,3) kernel, 초기 깊이(필터)= 1
# 3*3*1*32+32 = 320
# 3*3*32*64+64 = 18,496 : 그 다음 깊이(전 필터)는 32
# 3136*100 +100 = 313,700
# 100*10+10 = 1,010

# keras.utils.plot_model(model)

# keras.utils.plot_model(model, show_shapes=True, to_file='cnn-architecture.png', dpi=80)

# 모델 컴파일과 훈련

model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')
checkpoint_cb = keras.callbacks.ModelCheckpoint('best-cnn-model.h5')
early_stopping_cb = keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True)
# 에포크 조기종료를 알아서 해줬다..
history = model.fit(train_scaled, train_target, epochs=20, validation_data=(val_scaled, val_target), callbacks=[checkpoint_cb, early_stopping_cb])

# loss graph
import matplotlib.pyplot as plt
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.xlabel('epoch')
plt.ylabel('loss')
plt.legend(['train', 'val'])
plt.show()
# 조기 종료가 잘 이루어졌음을 확인

model.evaluate(val_scaled, val_target)

# 첫번째 이미지 샘플
plt.imshow(val_scaled[0].reshape(28,28), cmap='gray_r')
plt.show()

# 모델이 이 이미지에 대해 어떤 예측을 만드는지 확인
preds = model.predict(val_scaled[0:1])
print(preds)
# 출력 값 중에 e 문자는 지수 표현을 의미. 예를 들어 5e3은 5*10^3. 5e-3은 5*10^-3 
# 즉, 9번째 값만 1이고 나머지는 거의 0에 가까움. 즉, 9번째 클래스가 정답이라고 말하고 있다.

plt.bar(range(1,11), preds[0])
plt.xlabel('class')
plt.ylabel('prob')
plt.show()

classes = ['티셔츠','바지','스웨터','드레스','코트','샌달','셔츠','스니커즈','가방','앵클 부츠']
import numpy as np
print(classes[np.argmax(preds)])

# test set
test_scaled = test_input.reshape(-1,28,28,1) / 255.0
model.evaluate(test_scaled, test_target)
# test set의 경우 약 91% 기대할 수 있음. 그러므로 이 모델의 패션 분류기는 약 91프로 정도의 성능을 기대 가능.

# 이때 항상 테스트 세트는 모델을 출시하기 직전 딱 한 번만 사용해야 한다.** 굉장히 중요

# 합성곱 신경망의 시각화
# 합성곱 신경망은 특히 이미지에 있는 특징을 찾아 압축하는 데 뛰어난 성능을 보인다.

# 가중치 시각화
from tensorflow import keras
model = keras.models.load_model('best-cnn-model.h5')

model.layers

conv = model.layers[0]
print(conv.weights[0].shape, conv.weights[1].shape)

conv_weights = conv.weights[0].numpy()
# 가중치 배열의 평균과 표준편차
print(conv_weights.mean(), conv_weights.std())

# 가중치 분포
import matplotlib.pyplot as plt
plt.hist(conv_weights.reshape(-1,1))
plt.xlabel('weight')
plt.ylabel('count')
plt.show()

# 32개의 커널을 16개씩
fig, axs = plt.subplots(2, 16, figsize=(15,2))
for i in range(2):
  for j in range(16):
    # 배열에 있는 최대값과 최소값을 사용해 픽셀의 강도를 표현
    axs[i,j].imshow(conv_weights[:,:,0,i*16 +j], vmin=-0.5, vmax=0.5)
    axs[i,j].axis('off')
plt.show()

# 훈련하지 않은 빈 합성곱 신경망
no_training_model = keras.Sequential()
no_training_model.add(keras.layers.Conv2D(32, kernel_size=3, activation='relu', padding='same', input_shape=(28,28,1)))

# 첫번째 층의 가중치
no_training_conv = no_training_model.layers[0]
print(no_training_conv.weights[0].shape)

no_training_weights = no_training_conv.weights[0].numpy()
# 평균은 0에 더 가까워지고, 표준편차는 더 낮아졌다.
print(no_training_weights.mean(), no_training_weights.std())

# 이 그래프는 이전과 확실히 다르다. 그 이유는 텐서플로가 신경망의 가중치를 처음 초기화할 때 균등 분포에서 랜덤하게 값을 선택하기 때문
plt.hist(no_training_weights.reshape(-1,1))
plt.xlabel('weight')
plt.ylabel('count')
plt.show()

# 이 가중치 값을 다시 그림으로 출력
fig, axs = plt.subplots(2, 16, figsize=(15,2))
for i in range(2):
  for j in range(16):
    axs[i,j].imshow(no_training_weights[:,:,0,i*16+j], vmin=-0.5, vmax=0.5)
    axs[i,j].axis('off')
plt.show()

# 함수형 API
# 입력이 두 개이상, 출력이 2개이상일 수 있는데, 이 땐 Sequential() class를 사용하기 어렵다.
# 그래서 저런 경우 함수형 API를 사용

# dense1 = keras.layers.Dense(100, activation='sigmoid')
# dense2 = keras.layers.Dense(10, activation='softmax')

# 여기서 input은  InputLayer 클래스 객체인 Input() 함수를 사용해서 input을 만들어 줌.
# 입력에서 출력까지 층을 호출한 결과를 계속 이어주고 Model 클래스에 입력과 최종 출력을 지정함.
# inputs = keras.Input(shape=(784,))
# hidden = dense1(inputs)
# outputs = dense2(hidden)
# model = keras.Model(inputs, outputs)

# model 객체의 입력을 얻을 수 있다.
print(model.input)

conv_acti = keras.Model(model.input, model.layers[0].output)

# 특성 맵 시각화
(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()
plt.imshow(train_input[0], cmap='gray_r')
plt.show()

inputs = train_input[0:1].reshape(-1, 28,28,1) / 255.0
feature_maps = conv_acti.predict(inputs)
print(feature_maps.shape)

# 32개의 특성 맵 그리기
fig, axs = plt.subplots(4, 8, figsize=(15,8))
for i in range(4):
  for j in range(8):
    axs[i, j].imshow(feature_maps[0,:,:,i*8+j])
    axs[i,j].axis('off')
plt.show()

# 두번째 합성곱 층 모델
conv2_acti = keras.Model(model.input, model.layers[2].output)
inputs = train_input[0:1].reshape(-1,28,28,1) / 255.0
feature_maps = conv2_acti.predict(inputs)

print(feature_maps.shape)

# 64개 특성 맵 표현
fig, axs = plt.subplots(8,8,figsize=(12,12))
for i in range(8):
  for j in range(8):
    axs[i,j].imshow(feature_maps[0,:,:,i*8+j])
    axs[i,j].axis('off')
plt.show()

# 합성곱 층을 많이 쌓을수록 특성 맵에서 어떤 부위를 감지하는지 직관적으로 이해하기가 어렵다.
# 즉, 합성곱 신경망의 앞부분에 있는 합성곱 층은 이미지의 시각적인 정보를 감지하고 뒤쪽에 있는 합성곱 층은 앞쪽에서 감지한 시각적인 정보를 바탕으로 추상적인 정보를 학습.


# 정리
# 입력에 가까운 합성곱 층은 이미지에서 시각적인 정보나 패턴을 감지하도록 훈련된다.